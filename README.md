# AI Voice Assistant ğŸ¤–ğŸ™ï¸

A modular, Python-based AI voice assistant featuring speech recognition, interruptible text-to-speech, task automation, and real-time intelligence â€” designed with a clean backend architecture and GUI integration.

---

## âœ¨ Features

- ğŸ™ï¸ **Speech-to-Text** (always listening)
- ğŸ”Š **Text-to-Speech** (interruptible with voice command like â€œstopâ€)
- ğŸ§  **Decision-Making Model** to classify queries
- âš™ï¸ **Task Automation**
  - Open / close applications
  - Play media
  - System controls (volume, mute, etc.)
- ğŸŒ **Realtime Search Engine** for up-to-date queries
- ğŸ’¬ **Conversational Chatbot**
- ğŸ›‘ **CPU-style Interrupt Handling**
- ğŸ–¥ï¸ **GUI Interface**
- ğŸ§© **Modular Backend Design**

---

## ğŸ—ï¸ Project Structure

AI Assistant/
â”‚
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ Automation.py
â”‚ â”œâ”€â”€ Chatbot.py
â”‚ â”œâ”€â”€ Model.py
â”‚ â”œâ”€â”€ RealtimeSearchEngine.py
â”‚ â”œâ”€â”€ SpeechToText.py
â”‚ â”œâ”€â”€ TextToSpeech.py
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ Frontend/
â”‚ â”œâ”€â”€ GUI.py
â”‚ â””â”€â”€ Files/ # Runtime files (ignored in git)
â”‚
â”œâ”€â”€ RVC/
â”‚ â”œâ”€â”€ inference.py
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Main.py
â”œâ”€â”€ Requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸš€ How It Works

1. User speaks into the microphone
2. Speech is converted to text
3. Decision model classifies the query
4. Appropriate module is triggered:
   - Chatbot
   - Realtime search
   - Automation
5. Assistant responds via voice and GUI
6. User can interrupt at any time by saying **â€œstopâ€**

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/AI-Assistant.git
cd AI-Assistant
2ï¸âƒ£ Create a Virtual Environment
python -m venv .venv
.venv\Scripts\activate   # Windows

3ï¸âƒ£ Install Dependencies
pip install -r Requirements.txt

ğŸ” Environment Variables

Create a .env file in the project root:

Username=YourName
Assistantname=YourAssistant
GroqAPIKey=YOUR_GROQ_API_KEY
AssistantVoice=en-US-JennyNeural
InputLanguage=en


âš ï¸ .env is ignored by Git for security reasons.

â–¶ï¸ Run the Assistant
python Main.py


Make sure:

Microphone access is enabled

Chrome + matching ChromeDriver are installed (for speech recognition)

ğŸ§  Supported Commands Examples

â€œOpen WhatsAppâ€

â€œPlay musicâ€

â€œWhat is Python?â€

â€œWhatâ€™s todayâ€™s news?â€

â€œMute volumeâ€

â€œStopâ€ (interrupts speech and tasks)

ğŸ–¼ï¸ Image Generation

Image generation is currently disabled.
Planned future support:

Local Stable Diffusion

Cloud-based image APIs

ğŸ§© Future Enhancements

ğŸ”¥ Local image generation (Stable Diffusion)

ğŸ­ Emotion-based voice modulation

ğŸ§  Memory & personalization

â° Reminders & scheduling

ğŸŒ Multi-language support

âš ï¸ Security Notes

API keys are never committed

Runtime/generated files are ignored

GitHub secret scanning is enabled

ğŸ‘¤ Author

Shahid Mushtaq
Built with passion and persistence ğŸ’ª

ğŸ“œ License

This project is for educational and personal use.
License can be added later if open-sourced publicly.


---

## âœ… What you should do next

1. Create `README.md`
2. Paste the content above
3. Run:
```bash
git add README.md
git commit -m "Add README documentation"
git push
